{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PECGPT/PECGPT/blob/main/entrevistador_v2_Github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "1uip5Dm39zay",
        "outputId": "01ae3ac5-08a6-4b16-8f5d-cac71ece78d8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "#container {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  height: 90vh;\n",
              "}\n",
              "#output_area {\n",
              "  flex: 1;\n",
              "  overflow-y: auto;\n",
              "  background: #f8f8f8;\n",
              "  border: 1px solid #ccc;\n",
              "  padding: 8px;\n",
              "  min-height: 300px;\n",
              "}\n",
              "#input_area {\n",
              "  margin-top: 10px;\n",
              "}\n",
              "</style>\n",
              "<div id=\"container\">\n",
              "  <div id=\"output_area\" rows=\"30\"></div>\n",
              "  <div id=\"input_area\">\n",
              "    <textarea id=\"user_input\" rows=\"4\" cols=\"150\" maxlength=\"800\" placeholder=\" \"></textarea><br>\n",
              "    <button onclick=\"sendInput()\">Enviar</button>\n",
              "  </div>\n",
              "</div>\n",
              "<script>\n",
              "  function sendInput() {\n",
              "    const input = document.getElementById('user_input').value;\n",
              "    google.colab.kernel.invokeFunction('notebook.handle_input', [input], {});\n",
              "    document.getElementById('user_input').value = ''; // Clear textarea after sending\n",
              "  }\n",
              "    user_input.addEventListener('keydown', function(event) {\n",
              "    if (event.key === 'Enter' && !event.shiftKey) { // Check if Enter is pressed without the Shift key\n",
              "      event.preventDefault(); // Prevent the default action to avoid a new line\n",
              "      sendInput(); // Call the function to submit the text\n",
              "    }\n",
              "  });\n",
              "\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install openai > /dev/null 2>&1\n",
        "from google.colab import drive, userdata, output, files\n",
        "from openai import OpenAI\n",
        "import sys\n",
        "import os\n",
        "import string\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "testando = False\n",
        "testandofinal = False\n",
        "usarGPT4 = True\n",
        "\n",
        "#interface gráfica do Colab:\n",
        "html_code = '''\n",
        "<style>\n",
        "#container {\n",
        "  display: flex;\n",
        "  flex-direction: column;\n",
        "  height: 90vh;\n",
        "}\n",
        "#output_area {\n",
        "  flex: 1;\n",
        "  overflow-y: auto;\n",
        "  background: #f8f8f8;\n",
        "  border: 1px solid #ccc;\n",
        "  padding: 8px;\n",
        "  min-height: 300px;\n",
        "}\n",
        "#input_area {\n",
        "  margin-top: 10px;\n",
        "}\n",
        "</style>\n",
        "<div id=\"container\">\n",
        "  <div id=\"output_area\" rows=\"30\"></div>\n",
        "  <div id=\"input_area\">\n",
        "    <textarea id=\"user_input\" rows=\"4\" cols=\"150\" maxlength=\"800\" placeholder=\" \"></textarea><br>\n",
        "    <button onclick=\"sendInput()\">Enviar</button>\n",
        "  </div>\n",
        "</div>\n",
        "<script>\n",
        "  function sendInput() {\n",
        "    const input = document.getElementById('user_input').value;\n",
        "    google.colab.kernel.invokeFunction('notebook.handle_input', [input], {});\n",
        "    document.getElementById('user_input').value = ''; // Clear textarea after sending\n",
        "  }\n",
        "    user_input.addEventListener('keydown', function(event) {\n",
        "    if (event.key === 'Enter' && !event.shiftKey) { // Check if Enter is pressed without the Shift key\n",
        "      event.preventDefault(); // Prevent the default action to avoid a new line\n",
        "      sendInput(); // Call the function to submit the text\n",
        "    }\n",
        "  });\n",
        "\n",
        "</script>\n",
        "'''\n",
        "\n",
        "display(HTML(html_code))\n",
        "\n",
        "class SuppressOutput:\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout\n",
        "\n",
        "class OutputCapture:\n",
        "    def __init__(self, element_id):\n",
        "        self.element_id = element_id\n",
        "\n",
        "    def write(self, msg):\n",
        "        script = f'''\n",
        "        let box = document.getElementById('{self.element_id}');\n",
        "        box.innerHTML += `{msg}<br/>`; // Append new messages as HTML\n",
        "        '''\n",
        "        output.eval_js(script)\n",
        "\n",
        "    def flush(self):\n",
        "        pass\n",
        "\n",
        "\"\"\"\n",
        "CASO ESTEJA PUXANDO DO GOOGLE DRIVE (atualmente biblioteca no Github):\n",
        "    drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "\n",
        "#busca criterios4.py do Github\n",
        "with SuppressOutput():\n",
        "      !git clone https://github.com/PECGPT/PECGPT.git\n",
        "sys.path.append('/content/PECGPT')\n",
        "from criterios4 import *\n",
        "\n",
        "sys.stdout = OutputCapture('output_area')\n",
        "\n",
        "#variáveis globais\n",
        "i = 0  # contador de mensagens\n",
        "max_mensagens = 20\n",
        "prompt_tokens_35 = 0\n",
        "completion_tokens_35 = 0\n",
        "prompt_tokens_4 = 0\n",
        "completion_tokens_4 = 0\n",
        "criterios = criterios_ativos\n",
        "\n",
        "#históricos de mensagem:\n",
        "message_history = [] #message history completo\n",
        "message_history_cand = [] #apenas as mensagens com o candidato\n",
        "\n",
        "message_history_final = [] #usado para as avaliações finais.\n",
        "### implementar isto aqui.\n",
        "\n",
        "#tirar: ler de criterios.py\n",
        "#inst_inicial = \"\"\"Neste estágio inicial da entrevista, não aborde a escolha de curso diretamente. Tente conhecer melhor o perfil do candidato, sua familiaridade e interesse no Brasil, e seus hobbies e interesses pessoais.\\n Exemplos de primeiras perguntas possíveis: 'Você já esteve no Brasil?' 'Que cidades e regiões do Brasil você tem mais vontade de conhecer?'; 'Por que você escolheu estudar no exterior?' 'Você considerou estudar em algum país além do Brasil?'; 'Quais são suas matérias favoritas na escola?'; 'Qual é seu livro favorito e por que você gosta dele?'; 'Quem você listaria como suas inspirações pessoais?'\\n Não fique muito tempo em um só assunto: às vezes faça perguntas relacionadas à resposta anterior, e às vezes introduza um assunto novo. Tenha cuidado para não fazer perguntas redundantes, sobre coisas que o candidato já disse em mensagens anteriores, mesmo que falando de outro tema. Aborde um assunto por vez.\"\"\"\n",
        "\n",
        "\n",
        "def chat(inp, papel, modelo=\"gpt-3.5-turbo\", encerra = False):\n",
        "\n",
        "    global prompt_tokens_35, completion_tokens_35, prompt_tokens_4, completion_tokens_4, testando, usarGPT4\n",
        "    if not usarGPT4: modelo = \"gpt-3.5-turbo\"\n",
        "    if papel == \"candidato\":\n",
        "        inp = \"CAND: \" + inp\n",
        "        role = \"user\"\n",
        "        message_history_cand.append({\"role\": role, \"content\": f\"{inp}\"})\n",
        "    elif papel == \"supervisor\":\n",
        "        inp = \"SUPX: \" + inp\n",
        "        role = \"user\"\n",
        "    elif papel == \"system\":\n",
        "        role = \"system\"\n",
        "        message_history_cand.append({\"role\": role, \"content\": f\"{inp}\"})\n",
        "    message_history.append({\"role\": role, \"content\": f\"{inp}\"})\n",
        "\n",
        "\n",
        "    if encerra:\n",
        "      message_history_final.append({\"role\": role, \"content\": f\"{inp}\"})\n",
        "      msg_hist = message_history_final\n",
        "    else:\n",
        "      msg_hist = message_history\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=modelo,\n",
        "        messages = msg_hist\n",
        "    )\n",
        "\n",
        "    reply_content = completion.choices[0].message.content\n",
        "\n",
        "    if papel == \"candidato\":\n",
        "      message_history_cand.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
        "    if encerra:\n",
        "      message_history_final.append({\"role\": role, \"content\": f\"{reply_content}\"})\n",
        "    if papel != \"system\":\n",
        "      message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
        "\n",
        "\n",
        "\n",
        "    if modelo == \"gpt-3.5-turbo\":\n",
        "      prompt_tokens_35 += completion.usage.prompt_tokens\n",
        "      completion_tokens_35 += completion.usage.completion_tokens\n",
        "    else:\n",
        "      prompt_tokens_4 += completion.usage.prompt_tokens\n",
        "      completion_tokens_4 += completion.usage.completion_tokens\n",
        "\n",
        "    return reply_content\n",
        "\n",
        "\n",
        "def checa_resposta_int(s):\n",
        "    try:\n",
        "        int(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Supervisor:\n",
        "  global message_history, message_history_final, message_history_cand, inst_sistema, inst_inicial\n",
        "  inst = \"\"\n",
        "\n",
        "  def __init__(self, criterios, criterios_adicionais, inst, nome):\n",
        "    self.criterios = criterios\n",
        "    self.criterios_adicionais = criterios_adicionais\n",
        "    self.num_criterios = len(criterios)\n",
        "    self.num_criterios_adicionais = len(criterios_adicionais)\n",
        "    self.num_mensagens_iniciais = 4\n",
        "    self.freq_revisao_criterio = 4\n",
        "    self.avaliacoes = [-1 for _ in range(self.num_criterios)]\n",
        "    self.certezas = [0 for _ in range(self.num_criterios)]\n",
        "    self.avaliacoes_ad = [-1 for _ in range(self.num_criterios_adicionais)]\n",
        "    self.criterio_atual = self.define_criterio(0, self.certezas)\n",
        "    self.final = False\n",
        "    self.instrucoes = inst\n",
        "    self.relatorio = \"\"\n",
        "    self.relatorio_apendice = \"\"\n",
        "    self.nome = nome\n",
        "    chat(self.instrucoes[\"sistema\"], \"system\")\n",
        "\n",
        "\n",
        "  def chama_supervisor(self, i, user_input): #RETORNA TRUE SE GERAR MENSAGEM.\n",
        "    global max_mensagens, testando\n",
        "    if testando: print(\"chama supervisor chamado com i = \" + str(i))\n",
        "    if i == 0:\n",
        "      self.instrucao_inicial()\n",
        "      return True\n",
        "    if i == self.num_mensagens_iniciais:\n",
        "      self.criterio_atual = self.define_criterio(i, self.certezas)\n",
        "      self.informa_criterio(self.criterio_atual, user_input)\n",
        "      return True\n",
        "    if i > self.num_mensagens_iniciais and i % self.freq_revisao_criterio == self.num_mensagens_iniciais % self.freq_revisao_criterio and i < max_mensagens:\n",
        "#      self.certezas[self.criterio_atual], self.avaliacoes[self.criterio_atual] = self.avalia_certeza(self.criterio_atual, user_input), self.avalia_criterio(self.criterio_atual, user_input)\n",
        "      self.certezas[self.criterio_atual] = self.avalia_certeza(self.criterio_atual, user_input)\n",
        "      if testando: print(self.certezas, self.avaliacoes)\n",
        "      self.criterio_atual = self.define_criterio(i, self.certezas)\n",
        "      if self.criterio_atual == -1:\n",
        "        if testando: print(\"encerra entrevista chamado por esgotamento dos critérios em chama_supervisor.\")\n",
        "        self.encerra_entrevista(user_input)\n",
        "      else:\n",
        "        self.informa_criterio(self.criterio_atual, user_input)\n",
        "        return True #?\n",
        "    if i == max_mensagens:\n",
        "        if testando: print(\"encerra entrevista chamado por máx de mensagens em chama_supervisor.\")\n",
        "        self.encerra_entrevista(user_input)\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "  def define_criterio(self, i, certezas):\n",
        "     if i < self.num_mensagens_iniciais:\n",
        "      return 0\n",
        "     menor = min(certezas)\n",
        "     if menor == 3:\n",
        "       return -1 # -1 indica final da entrevista, já que todos os critérios estão preenchidos com certeza máxima.\n",
        "     else:\n",
        "      if testando: print(\"O próximo critério é: \", certezas.index(menor))\n",
        "      return certezas.index(menor)\n",
        "\n",
        "  def informa_criterio(self, crit, user_input):\n",
        "    mensagem = \"Ignore minha última instrução, pois passamos para outra fase da entrevista. Nesta fase da entrevista a prioridade é: \\n\\n\" + self.criterios[crit][\"prompt_entrevista\"]\n",
        "    mensagem += \"\\n\\nAgora você vai retomar a conversa com o candidato. Suas mensagens devem seguir o objetivo acima. Lembre: você deve responder perguntas ou solicitações de informação APENAS do supervisor, não do candidato. \\\n",
        "    Se o candidato fizer perguntas ou solicitar informações que não sejam relacionadas à entrevista ou solicitar informação de qualquer outro tipo, diga gentilmente que não pode responder e recomende que visite o site do PEC-G, converse com o operador no Posto diplomático brasileiro mais próximo ou outra fonte relevante. A última \\\n",
        "    mensagem do candidato foi: CAND: \" + user_input + \" Responda esta mensagem com uma pergunta para o candidato, conforme as orientações acima. Não inclua nada além da mensagem para o candidato.\"\n",
        "#    print(mensagem)\n",
        "    resposta = chat(mensagem, \"supervisor\")\n",
        "    if testando: print(\"critério em avaliação atualizado para \" + str(crit) + \" pela função informa_criterio\")\n",
        "    print(resposta)\n",
        "    #criar mensagem de reforço com system?\n",
        "\n",
        "  def instrucao_inicial(self):\n",
        "    mensagem = self.instrucoes[\"inicial\"] + \"\\nResponda esta mensagem com sua primeira mensagem para o candidato, iniciando a entrevista. Não inclua nada além da sua mensagem para o candidato.\"\n",
        "    resposta = chat(mensagem, \"supervisor\")\n",
        "    if testando: print(\"instrucao_inicial chamado, com mensagem inicial: \" + mensagem)\n",
        "    print(resposta)\n",
        "\n",
        "\n",
        "  def avalia_certeza(self, crit, user_input, encerra=False):\n",
        "    mensagem = \"\"\n",
        "#    prompt_local = \"responda apenas com um dígito: '3' se todos os itens foram abordados e o candidato forneceu informação detalhadas sobre todos os pontos, e/ou prestou informações tais que nenhuma outra pegunta sobre o tema seria pertinente no contexto da entrevista; '2' se todos os quase todos foram abordados, mas as informações fornecidas pelo candidato não são muito detalhadas; '1' se diversos itens importantes não foram abordados ainda, ou o candidato não voluntariou informação suficiente sobre parte significativa deles; e '0' se todos ou a maior parte dos itens para considerar nessa avaliação não foram abordados ou foram respondidos de forma vaga ou evasiva pelo candidato.\"\n",
        "\n",
        "    if testando: print(f\"avalia_certeza chamado com encerra = {encerra} e crit = {crit}\")\n",
        "\n",
        "    if not encerra:\n",
        "      mensagem += \"CAND: \" + user_input + \"\\n\"\n",
        "      mensagem += \"SUPX: a última mensagem do candidato está acima. Agora, vamos fazer uma pausa na conversa com o candidato para uma avaliação.\\n\"\n",
        "\n",
        "#    mensagem += \"SUPX: Revise agora toda sua conversa com o candidato e considere quanta informação foi fornecida pelo candidato, para avalia-lo no critério a seguir.\\n\"\n",
        "    mensagem += \"Descrição do critério: \" + self.criterios[crit][\"descrição\"] + \".\\n\\n\"\n",
        "    mensagem += self.criterios[crit][\"prompt_certeza\"] + \"\\n\"\n",
        "    mensagem += self.instrucoes[\"certeza_1\"]\n",
        "    if testando: print(\"Consulta de critérios: \" + mensagem)\n",
        "\n",
        "    if not encerra:\n",
        "      resp = chat(mensagem, \"supervisor\")\n",
        "      if testando: print(\"avaliação de certeza chamada. Mensagem: \" + mensagem + \"\\n\\nResposta: \" + resp + \"\\n\")\n",
        "#      chat(mensagem, \"supervisor\")\n",
        "      mensagem = \"SUPX: \" + self.instrucoes[\"certeza_2\"]\n",
        "      resposta = chat(mensagem, \"supervisor\")\n",
        "      if testando: print(\"avaliação de certeza chamada. Segunda leva de mensagens: Mensagem: \" + mensagem + \"\\n\\nResposta: \" + resposta + \"\\n\")\n",
        "\n",
        "      if not checa_resposta_int(resposta):\n",
        "        mensagem = \"Responda apenas com um dígito numérico, conforme instruído. Não inclua mais nada na sua mensagem, apenas um caractere numérico.\"\n",
        "        resposta = chat(mensagem, \"supervisor\") #ver se ok com o 3.5\n",
        "      cert = int(resposta) #TODO: revisar para o caso de precisar insistir; fazer um loopzinho com checa_resposta_int\n",
        "\n",
        "    if encerra:\n",
        "      resposta = chat(mensagem, \"supervisor\", modelo=\"gpt-4o-2024-05-13\", encerra=True)\n",
        "      if testando: print(resposta)\n",
        "      mensagem = \"SUPX: \" + self.instrucoes[\"certeza_2\"]\n",
        "      resposta = chat(mensagem, \"supervisor\", modelo=\"gpt-4o-2024-05-13\", encerra=True)\n",
        "\n",
        "      if not checa_resposta_int(resposta):\n",
        "        mensagem = \"Responda apenas com um dígito numérico, correspondente à categoria.\"\n",
        "        resposta = chat(mensagem, \"supervisor\") #ver se ok com o 3.5\n",
        "\n",
        "      cert = int(resposta) #TODO: revisar para o caso de precisar insistir; fazer um loopzinho com checa_resposta_int\n",
        "\n",
        "    return cert\n",
        "\n",
        "  def avalia_criterio(self, crit, user_input, enc=False):\n",
        "    global testandofinal\n",
        "    mensagem = \"\"\n",
        "    if testando: print(\"avalia_criterio chamado com encerra = True e crit = \" + str(crit))\n",
        "    if not enc:\n",
        "      mensagem += \"\\\"CAND: \" + user_input + \"\\\"\\n\"\n",
        "      mensagem += \"SUPX: a última mensagem do candidato está acima. Agora, vamos fazer uma pausa na conversa com o candidato para uma avaliação.\\n\"\n",
        "#      if testando: print(\"avalia_criterio chamado com encerra = False\")\n",
        "\n",
        "    mensagem += \"Revise agora, cuidadosamente, todo o histórico da sua conversa com o candidato. \" + self.criterios[crit][\"prompt_avaliação\"] + \"\\n Classifique o candidato em uma dessas categorias: \"  + self.criterios[crit][\"categorias\"] + \" Antes de classificar o candidato, explique seu raciocínio sobre cada um dos pontos levantados para essa avaliação, atendo-se ao que foi conversado entre você e o candidato. Esteja atento para nuances: há informações incorretas ou vagas nas falas do candidato? O candidato mostrou-se reticente ao abordar algum ponto? O candidato pode estar sendo otimista demais sobre sua situação financeira? Ao final, junte todas as suas considerações e escolha uma das categorias.\"\n",
        "    resposta = chat(mensagem, \"supervisor\", modelo=\"gpt-4o-2024-05-13\", encerra=enc)\n",
        "    if enc:\n",
        "       self.relatorio_apendice += \"\\n\\nANÁLISE SOBRE O CRITÉRIO \" + self.criterios[crit][\"nome\"].upper() + \":\\n\\n \" + resposta + \"\\n\\n\"\n",
        "       if testandofinal:\n",
        "              print(\"mensagem para avalia_criterios:\", mensagem, \"resposta: \", resposta)\n",
        "    mensagem = \"Agora, condense sua mensagem anterior informando apenas o dígito que identifica a categoria em que está classificando o candidato. Não inclua mais nada na sua mensagem, apenas um caractere numérico para indicar a categoria.\"\n",
        "    resposta = chat(mensagem, \"supervisor\", encerra=enc)\n",
        "    if testando: print(\"resposta foi: \", resposta)\n",
        "    if not checa_resposta_int(resposta):\n",
        "      mensagem = \"Responda apenas com um dígito numérico, correspondente à categoria.\"\n",
        "      resposta = chat(mensagem, \"supervisor\") #TODO: revisar para o caso de precisar insistir; fazer um loopzinho com checa_resposta_int\n",
        "\n",
        "    result = int(resposta)\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "  def avalia_criterio_adicional(self, crit):\n",
        "    global testandofinal\n",
        "    if testando: print(f\"avalia_criterio_adicional chamado com  crit = {crit}\")\n",
        "\n",
        "    mensagem = \"\"\"SUPX: A entrevista acabou. Agora, vamos avaliar alguns critérios mais delicados, que exigirão uma leitura atenta de toda a conversa com o candidato até agora.\n",
        "    Considere que o candidato pode não estar falando a verdade, pode ter um otimismo injustificado ou estar se baseando em informações equivocadas.\n",
        "    É um trabalho de detetive! Preste muita atenção a pistas que o candidato pode ter dado sem querer. Este é um dos 'critérios especiais'\\n\\n\"\"\"\n",
        "\n",
        "    mensagem += self.criterios_adicionais[crit][\"prompt_avaliação\"] + \"\\n Veja se há informação suficiente, nas mensagens do candidato, para classificá-lo em uma dessas categorias. Se houver, escolha uma categoria e justifique detalhadamente sua resposta.\"\n",
        "    resposta = chat(mensagem, \"supervisor\", modelo=\"gpt-4o-2024-05-13\", encerra=True)\n",
        "    self.relatorio_apendice += \"\\n\\nAVALIAÇÃO SOBRE O CRITÉRIO ADICIONAL \" + self.criterios_adicionais[crit][\"nome\"].upper() + \":\\n\\n\" + resposta + \"\\n\\n\"\n",
        "    if testandofinal:\n",
        "        print(\"\\n\\n\\nmensagem para avalia_criterio_adicional:\", mensagem, \"\\n\\n\\nresposta: \", resposta)\n",
        "    mensagem = \"Agora, condense sua mensagem anterior informando apenas o dígito que identifica a categoria em que está classificando o candidato. Não inclua mais nada na sua mensagem, apenas um caractere numérico para indicar a categoria. Se não houver informação suficiente para essa avaliação, responda -1\"\n",
        "    resposta = chat(mensagem, \"supervisor\", encerra=True)\n",
        "    #if testando: print(\"Mensagem de consulta sobre critério adicional: \", mensagem)\n",
        "\n",
        "    if not checa_resposta_int(resposta):\n",
        "      mensagem = \"Responda apenas com um dígito numérico, correspondente à categoria.\"\n",
        "      resposta = chat(mensagem, \"supervisor\") #ver se ok com o 3.5\n",
        "    result = int(resposta) #revisar para o caso de precisar insistir; fazer um loopzinho com checa_resposta_int\n",
        "    return result\n",
        "\n",
        "\n",
        "  def encerra_entrevista(self, user_input):\n",
        "    global i, prompt_tokens_35, completion_tokens_35, prompt_tokens_4, completion_tokens_4, testando, testandofinal, message_history_cand, message_history_final #TODO: global i pq? Muita coisa global, fazer uma classe para msghistory\n",
        "\n",
        "    if testando:\n",
        "      print(f\"encerra_entrevista chamado com self.final ={self.final}.\")\n",
        "    try:\n",
        "      message_history_final = list(message_history_cand)\n",
        "    except:\n",
        "      print(\"falha no manuseio dos message histories!\")\n",
        "\n",
        "    if self.final:\n",
        "      return True\n",
        "\n",
        "    self.relatorio = \"Candidato: \" + self.nome + \"\\n\\n\\n\"\n",
        "\n",
        "    mensagem = \"\\n CAND: \" + user_input + \"\\n\"\n",
        "    message_history_final.append({\"role\": \"user\", \"content\": f\"{mensagem}\"})\n",
        "    message_history_cand.append({\"role\": \"user\", \"content\": f\"{mensagem}\"})\n",
        "    mensagem += \"SUPX: a última mensagem do candidato está acima. Já podemos encerrar a entrevista. Responda com uma mensagem para o candidato encerrando a entrevista de forma cordial e desejando boa sorte.\" #checar o fluxo no caso em que encerra_entrevista é chamado por critérios esgotados.\n",
        "    resposta = chat(mensagem, \"supervisor\")\n",
        "    print(resposta)\n",
        "    print(\"\\n\\n\\n####\\n A entrevista acabou. Gerando o arquivo de análise (aguarde)\")\n",
        "\n",
        "    for i in range(self.num_criterios):\n",
        "        if testando: print(f\"entrou no loop com encerra = True e num_criterios = {self.num_criterios}. Está em {i}\")\n",
        "        self.certezas[i] = self.avalia_certeza(i, \"\", encerra=True)\n",
        "        self.avaliacoes[i] = self.avalia_criterio(i, \"\", enc=True)\n",
        "        if testandofinal: print(f\"critério {self.criterios[i]['nome']} classificado na categoria {self.avaliacoes[i]} com certeza {self.certezas[i]}\")\n",
        "        self.relatorio += f\"critério {self.criterios[i]['nome']} classificado na categoria {self.avaliacoes[i]} com certeza {self.certezas[i]} \\n\"\n",
        "\n",
        "    for i in range (self.num_criterios_adicionais): #TODO: um toggle aqui se não houver critérios adicionais, por modularidade.\n",
        "        self.avaliacoes_ad[i] = self.avalia_criterio_adicional(i)\n",
        "        if testandofinal: print(\"critério adicional \" + self.criterios_adicionais[i][\"nome\"] + \" classificado na categoria \" + str(self.avaliacoes_ad[i]))\n",
        "        self.relatorio += \"critério adicional\" + self.criterios_adicionais[i][\"nome\"] + \" classificado na categoria \" + str(self.avaliacoes_ad[i]) + \"\\n\"\n",
        "\n",
        "    mensagem = self.instrucoes[\"resumo\"]\n",
        "    resposta = chat(mensagem, \"supervisor\", modelo=\"gpt-4o-2024-05-13\")\n",
        "#    print(\"\\n\\nPerfil do candidato:\\n\\n\", resposta)\n",
        "    self.relatorio += \"PERFIL DO CANDIDATO: \\n\\n \" + resposta + \"\\n\\n\\n\"\n",
        "    print(\"Avaliação nos critérios principais: \", self.certezas, self.avaliacoes + \"\\n\\n\")\n",
        "    print(\"Avaliação nos critérios adicionais: \", self.avaliacoes_ad + \"\\n\\n\\n\\n\\n\")\n",
        "    if testando:\n",
        "      print(\"message history com o candidato: \", message_history_cand)\n",
        "      print(\"message history para avaliação final: \", message_history_final)\n",
        "\n",
        "    self.relatorio += self.relatorio_apendice\n",
        "    arquivo = self.nome +  \".txt\"\n",
        "    print(arquivo)\n",
        "    with open(arquivo, \"w\") as file:\n",
        "        file.write(self.relatorio)\n",
        "        files.download(arquivo)\n",
        "    arquivo = self.nome + \" historico.txt\"\n",
        "    with open(arquivo, \"w\") as file:\n",
        "        file.write(message_history_final)\n",
        "        files.download(arquivo)\n",
        "    print(f\"\\nArquivos {self.nome}.txt e {arquivo} gerados.\")\n",
        "\n",
        "#    if testandofinal:\n",
        "    if True:\n",
        "        print(f\"Uso de tokens:\\n prompts 3.5: {prompt_tokens_35}, completions 3.5: {completion_tokens_35}, prompt 4o: {prompt_tokens_4}, completion 4o: {completion_tokens_4}\")\n",
        "        custo = prompt_tokens_35 * 0.0000005 + completion_tokens_35 * 0.0000015 + prompt_tokens_4 * 0.000005 + completion_tokens_4 * 0.000015\n",
        "        print(\"custo estimado: \" + str(custo))\n",
        "    self.final = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#setup inicial. TODO: Alterar depois quando tiver como puxar os dados do candidato.\n",
        "mensagem_inicial = \"Olá! Informe seu nome para começar.\\n\" #TODO: revisar depois.\n",
        "print(mensagem_inicial)\n",
        "message_history.append({\"role\": \"assistant\", \"content\": f\"{mensagem_inicial}\"})\n",
        "message_history_cand.append({\"role\": \"assistant\", \"content\": f\"{mensagem_inicial}\"})\n",
        "nome = \"\"\n",
        "\n",
        "supervisor = Supervisor(criterios, criterios_adicionais, inst, nome)\n",
        "\n",
        "\"\"\"\n",
        "for i in range(15):\n",
        "    if not supervisor.final:\n",
        "     user_input = input(\"> \")\n",
        "    if i == 0:\n",
        "       message_history.append({\"role\" : \"user\", \"content\": \"EST: \"f\"{user_input}\"})\n",
        "    if not supervisor.chama_supervisor(i, user_input): # A chamada ao supervisor retorna True quando já resulta na mensagem seguinte ao candidato.\n",
        "      print(chat(user_input, \"candidato\"))\n",
        "    if supervisor.final: break\n",
        "    print()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def handle_input(user_input):\n",
        "    global i, nome\n",
        "    print(\"> \" + user_input)\n",
        "    if i == 0:\n",
        "        message_history.append({\"role\": \"user\", \"content\": f\"CAND: {user_input}\"}) #TODO: duplicado? necessário?\n",
        "        message_history_cand.append({\"role\": \"user\", \"content\": f\"CAND: {user_input}\"}) #TODO: duplicado? necessário?\n",
        "        # Create translation table\n",
        "        translator = str.maketrans('', '', string.punctuation)\n",
        "        supervisor.nome = user_input.translate(translator)\n",
        " #       i = 19 #usado para pular para o final para fins de teste.\n",
        "    if supervisor.final:\n",
        "        return\n",
        "    if not supervisor.chama_supervisor(i, user_input):\n",
        "        response = chat(user_input, \"candidato\")\n",
        "        print(response)\n",
        "    if i >= max_mensagens:\n",
        "        if supervisor.final == False:\n",
        "            supervisor.encerra_entrevista(user_input)\n",
        "        return\n",
        "    i += 1\n",
        "\n",
        "output.register_callback('notebook.handle_input', handle_input)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L1zLM5ekEPbI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM_vWYkRkPqU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmLS_LKHj456",
        "outputId": "ee5a5d70-1d8e-4889-d1ed-2a1375d805a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}